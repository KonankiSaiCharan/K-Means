{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the necessary packages\n",
    "import pandas as pd\n",
    "import mnist\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "import scipy.misc\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from scipy import sparse\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required Pixels\n",
    "PixelValuesTrain = mnist.train_images()\n",
    "PixelValuesTest = mnist.test_images()\n",
    "#Combining the test and train as KMeans is an unsupervised learning algo\n",
    "AllPixelValues = np.concatenate((PixelValuesTrain,PixelValuesTest),axis = 0)\n",
    "\n",
    "#Getting the required labels\n",
    "LabelValuesTrain = mnist.train_labels()\n",
    "LabelValuesTest = mnist.test_labels()\n",
    "#Combining the test and train as KMeans is an unsupervised learning algo\n",
    "AllLabelValues = np.concatenate((LabelValuesTrain,LabelValuesTest),axis = 0)\n",
    "\n",
    "#Using the reshape function to change the dimensions\n",
    "CompressedAllPixelValues = AllPixelValues.reshape((AllPixelValues.shape[0], AllPixelValues.shape[1] * AllPixelValues.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Clusters\n",
    "def createClusters(DataToBeClustered, countOfClusters, randomNess, numIterations, Labels, dataType):\n",
    "    #Using this variable we decide the number of times the loop should iterate so that it does not go \n",
    "    #to infinite loop\n",
    "    iterationCount = range(numIterations)\n",
    "    \n",
    "    #Initial centroid selection is made using random selection\n",
    "    Range = np.random.RandomState(randomNess)\n",
    "    Index = Range.permutation(DataToBeClustered.shape[0])[:countOfClusters]\n",
    "    centroids = DataToBeClustered[Index]\n",
    "    FunctiontobeReduced = list()\n",
    "    \n",
    "    for itcount in iterationCount:\n",
    "        #In this step we group all the points closest to centroids\n",
    "        Class = pairwise_distances_argmin_min(DataToBeClustered, centroids)\n",
    "        FunctiontobeReduced.append(sum(Class[1] ** 2))\n",
    "        \n",
    "        #Using the above formed groups we calculate the mean\n",
    "        if dataType == \"MNIST\":\n",
    "            latestCentroids = np.array([DataToBeClustered[Class[0] == Index].mean(0)\n",
    "                                        for Index in range(countOfClusters)])\n",
    "            \n",
    "        if dataType == \"newsData\":\n",
    "            latestCentroids = np.array([DataToBeClustered[Class[0] == Index].mean(0)\n",
    "                                for Index in range(countOfClusters)])\n",
    "            latestCentroids = latestCentroids.reshape((latestCentroids.shape[0], latestCentroids.shape[1] * latestCentroids.shape[2]))\n",
    "        \n",
    "        #If the old and the new centroids remain the same then we say that the algo has converged\n",
    "        if np.all(centroids == latestCentroids):\n",
    "            break\n",
    "        centroids = latestCentroids\n",
    "    OriginalLabels = Labels\n",
    "    maxCluster = list()\n",
    "    clusterDensity = list()\n",
    "    clusterDen = list()\n",
    "    GIImp = list()\n",
    "    OriginalLabelsLength = len(OriginalLabels)\n",
    "    for IndexOfCluster in range(centroids.shape[0]):\n",
    "        Cap = (Class[0] == IndexOfCluster)\n",
    "        clusterDensity.append(sum(np.bincount(OriginalLabels[Cap])))\n",
    "        GI = 0\n",
    "        for i in range(len((np.bincount(OriginalLabels[Cap])))):\n",
    "            GI += (((np.bincount(OriginalLabels[Cap]))[i])/sum(np.bincount(OriginalLabels[Cap]))) ** 2\n",
    "        GIImp.append(1 - GI)\n",
    "        maximum = np.argmax(np.bincount(OriginalLabels[Cap]))\n",
    "        maxCluster.append(np.bincount(OriginalLabels[Cap]).max())\n",
    "    maxCluster_sum = sum(maxCluster)\n",
    "    purityValue = maxCluster_sum/OriginalLabelsLength\n",
    "    GiniUnits = 0\n",
    "    sumValue = 0\n",
    "    for i in range(centroids.shape[0]):\n",
    "        sumValue += GIImp[i]*clusterDensity[i]\n",
    "    GiniValue = sumValue/sum(clusterDensity)\n",
    "    return centroids, Class, purityValue, GiniValue, FunctiontobeReduced, clusterDensity, maxCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroidsMNIST, ClassMNIST, purityMNIST, GiniMNIST, objMNIST,c,f = createClusters(CompressedAllPixelValues, 10, randomNess = 15, numIterations = 10000,Labels = AllLabelValues, dataType = \"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56669298143518898"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GiniMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56647142857142863"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purityMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's increase the number of centroids and check the purity and gini...\n",
    "#As we can see from the below we can say that the values got better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroidsMNIST1, ClassMNIST1, purityMNIST1, GiniMNIST1, objMNIST1,c3,f3 = createClusters(CompressedAllPixelValues, 20, randomNess = 15, numIterations = 10000,Labels = AllLabelValues, dataType = \"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39831815957090327"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GiniMNIST1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70228571428571429"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purityMNIST1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtaining the data required to do analysis on 20 NG\n",
    "newsData = fetch_20newsgroups(subset='train')\n",
    "converter = TfidfVectorizer(stop_words='english')\n",
    "#newsData vectorized for consumption\n",
    "newsDataConsumable = converter.fit_transform(newsData.data)\n",
    "AllLabelsValuesnewData = newsData.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroidsNewsData, ClassNewsData, purityNewsData, giniNewsData, objNewsData,c1,f1 = createClusters(newsDataConsumable, 20,numIterations = 10000,randomNess = 32,Labels = AllLabelsValuesnewData, dataType = \"newsData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759002961658089"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giniNewsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33082906133993284"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purityNewsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroidsNewsData, ClassNewsData, purityNewsData, giniNewsData, objNewsData,c1,f1 = createClusters(newsDataConsumable, 10,numIterations = 10000,randomNess = 32,Labels = AllLabelsValuesnewData, dataType = \"newsData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81382690234674493"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giniNewsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26330210358847445"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purityNewsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtaining the fashion data to perform analysis\n",
    "def getFashionData(path, kind='train'):\n",
    "    import numpy as np\n",
    "    import gzip\n",
    "    import os\n",
    "    \n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    \n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionDataValues, fashionDataLabels = getFashionData(\"C:\\\\Users\\\\saich\\\\Desktop\\\\UnsupervisedML\\\\fashion-mnist-master\\\\data\\\\fashion\", kind='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroidsFashion, ClassFashion, purityFashion, giniFashion, objFashion, c2,f2 = createClusters(fashionDataValues, 10,numIterations = 10000,randomNess = 32,Labels = fashionDataLabels, dataType = \"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57916666666666672"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purityFashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53539512042792337"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giniFashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroidsFashion, ClassFashion, purityFashion, giniFashion, objFashion, c2,f2 = createClusters(fashionDataValues, 20,numIterations = 10000,randomNess = 32,Labels = fashionDataLabels, dataType = \"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64744999999999997"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purityFashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45386331299278959"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giniFashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hence, we can see that for MNIST, 20NG and Fashion datasets we have calculated purity, gini and objective functions.\n",
    "2. And we have also experimented by changing the number of clusters and it is evident that the purity and gini become better when the cluster count is high and become worse when the cluster count is low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
